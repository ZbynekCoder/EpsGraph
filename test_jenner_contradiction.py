import os
import shutil
import sys
from dotenv import load_dotenv

sys.path.append(os.getcwd())

from src.proprag.PropRAG import PropRAG
from src.proprag.utils.config_utils import BaseConfig
from src.proprag.graph_beam_search import BeamSearchPathFinder
from src.proprag.reasoning.consistency_validator import ConsistencyValidator
from src.proprag.utils.misc_utils import compute_mdhash_id

load_dotenv()

# === é…ç½® ===
my_api_key = "sk-ZHv49kkwqj8lg05MCzGYF3YFKGwZzdizk419Gv8ylT1pjhOt"
my_base_url = "https://svip.xty.app/v1"
my_model_name = "gpt-4.1-mini"
output_dir = "outputs/jenner_test"


def main():
    # 1. ç¯å¢ƒæ¸…ç†ä¸åˆå§‹åŒ–
    if os.path.exists(output_dir):
        shutil.rmtree(output_dir)

    config = BaseConfig(
        save_dir=output_dir,
        llm_name=my_model_name, llm_base_url=my_base_url, api_key=my_api_key,
        embedding_model_name="/data-share/yeesuanAI08/zhangboyang/EpsGraph/models/NV-Embed-v2",
        is_directed_graph=True,
        force_index_from_scratch=False  # æ‰‹åŠ¨æ§åˆ¶
    )

    print("ğŸš€ Initializing PropRAG for Jenner Test...")
    if os.path.exists(output_dir): shutil.rmtree(output_dir)
    os.makedirs(output_dir, exist_ok=True)

    rag = PropRAG(global_config=config)
    searcher = BeamSearchPathFinder(rag)
    validator = ConsistencyValidator(rag.llm_model)

    # === 2. æ•…äº‹æµ ===
    story_stream = [
        # Time 1: å»ºç«‹äººè®¾
        "Jenner was a cynical rat who loudly opposed Nicodemus's Plan to move the colony to Thorn Valley.",

        # Time 2: å¼ºåŒ–åŠ¨æœº
        "He argued that stealing electricity and food from humans was easier and better than working hard in the fields.",

        # Time 3: çŸ›ç›¾çˆ†å‘ (OOC)
        "Jenner announced that he agreed wholeheartedly with The Plan and couldn't wait to start farming."
    ]

    print("\nğŸ¬ --- Action! ---")

    for i, doc in enumerate(story_stream):
        print(f"\n\nğŸ“ [Time Step {i + 1}] Input: \"{doc}\"")

        # å¢é‡ Indexing
        rag.global_config.force_index_from_scratch = False
        rag.index([doc])

        # è·å–æœ€æ–°çš„ Belief è¿›è¡Œå®¡è®¡
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å–æœ€åä¸€ä¸ªè¢«æ·»åŠ çš„ Belief
        # åœ¨çœŸå®çš„æµå¼åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬åº”è¯¥ç›‘å¬ "New Belief Event"
        last_prop_key = list(rag.proposition_to_entities_map.keys())[-1]
        last_belief = rag.proposition_to_entities_map[last_prop_key]

        agent_name = last_belief["source"]
        new_statement = last_belief["text"]

        # é˜²å¾¡ï¼šå¦‚æœæå–å‡ºçš„ source æ˜¯ GlobalContextï¼Œå¯èƒ½ä¸éœ€è¦å®¡è®¡ï¼Œæˆ–è€…å®¡è®¡ Narrative ä¸€è‡´æ€§
        # è¿™é‡Œæˆ‘ä»¬ä¸»è¦å…³æ³¨ Jenner
        if agent_name == "GlobalContext" and "Jenner" in new_statement:
            # å¦‚æœ LLM æŠŠ "Jenner agreed" æå–ä¸ºå®¢è§‚äº‹å® (Source=Global)ï¼Œ
            # æˆ‘ä»¬å…¶å®åº”è¯¥å®¡è®¡çš„æ˜¯ Jenner è¿™ä¸ªå®ä½“ã€‚
            # è¿™æ˜¯ä¸€ä¸ªé«˜é˜¶æŠ€å·§ï¼Œæš‚ä¸”å‡è®¾ LLM èƒ½æ­£ç¡®æå– Source=Jenner
            pass

        print(f"ğŸ” Auditing Agent: {agent_name}")
        print(f"   Statement: \"{new_statement}\"")

        # 1. æ£€ç´¢ Ego-centric Memories
        agent_key = compute_mdhash_id(agent_name, prefix="entity-")

        # å¼ºåˆ¶åˆ·æ–°ç¼“å­˜ (å› ä¸ºæ˜¯åŒä¸€ä¸ª searcher å¯¹è±¡)
        searcher._build_indexes()

        # æŸ¥æ‰¾è¯¥ Agent è¿‡å»çš„æ‰€æœ‰ Beliefs
        # æ³¨æ„ï¼šæˆ‘ä»¬è¿™é‡Œæ¨¡æ‹Ÿçš„æ˜¯ "è‡ªæˆ‘åæ€"ï¼Œæ‰€ä»¥æ£€ç´¢æ‰€æœ‰å…³è” Belief
        # ç®€å•èµ·è§ï¼Œæˆ‘ä»¬ç›´æ¥è·å– Agent èŠ‚ç‚¹ç›´è¿çš„æ‰€æœ‰ Agency è¾¹

        if agent_key not in searcher.agent_beliefs_cache:
            print("   (No prior memories found for this agent)")
            memories = []
        else:
            belief_keys = searcher.agent_beliefs_cache[agent_key]
            memories = []
            for bk in belief_keys:
                if bk == last_prop_key: continue  # è·³è¿‡å½“å‰è¿™å¥

                b_data = rag.proposition_to_entities_map.get(bk)
                if b_data:
                    memories.append({
                        "text": b_data["text"],
                        "source": b_data["source"],
                        "nodes": [agent_key, bk],
                        "texts": [agent_name, b_data["text"]]  # ä¸ºäº†é€‚é… Validator æ¥å£
                    })

            print(f"   Found {len(memories)} prior memories.")
            for m in memories:
                print(f"   - {m['text']}")

        # 2. è°ƒç”¨ Validator
        result = validator.validate(
            agent_name=agent_name,
            new_belief_text=new_statement,
            retrieved_memories=memories  # Validator å†…éƒ¨ä¼šå¤„ç†æ ¼å¼
        )

        print(f"ğŸ¤– Validation Result:")
        print(f"   Status: {result['status']}")
        print(f"   Reasoning: {result['reasoning']}")

        if i == 2:  # æœ€åä¸€æ­¥
            if result['status'] == "Inconsistent":
                print("\nâœ… SUCCESS: Inconsistency detected!")
            else:
                print("\nâŒ FAILURE: Failed to detect inconsistency.")


if __name__ == "__main__":
    main()
