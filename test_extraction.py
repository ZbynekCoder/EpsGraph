import os
import sys

# Á°Æ‰øùËÉΩÊâæÂà∞È°πÁõÆÊ†πÁõÆÂΩï
sys.path.append(os.getcwd())

from src.proprag.utils.config_utils import BaseConfig
from src.proprag.llm.openai_gpt import CacheOpenAI  # Êó¢ÁÑ∂ infer Áî®ÁöÑÊòØÂêåÊ≠• clientÔºåËøôÈáåÁõ¥Êé•Áî® OpenAI_GPT
from src.proprag.information_extraction.proposition_extraction import PropositionExtractor


def test_belief_extraction():
    # === API ÈÖçÁΩÆ (ËØ∑Âú®Ê≠§Â§ÑÂ°´ÂÖ•‰Ω†ÁöÑÁúüÂÆû‰ø°ÊÅØ) ===

    # Á§∫‰æã1Ôºö‰ΩøÁî® DeepSeek API
    # api_key = "sk-xxxxxxxx"
    # base_url = "https://api.deepseek.com"
    # model_name = "deepseek-chat"

    # Á§∫‰æã2Ôºö‰ΩøÁî® Á°ÖÂü∫ÊµÅÂä® (SiliconFlow) Qwen
    # api_key = "sk-xxxxxxxx"
    # base_url = "https://api.siliconflow.cn/v1"
    # model_name = "Qwen/Qwen2.5-14B-Instruct"

    # ËØ∑Âú®ËøôÈáåÂ°´ÂÖ•‰Ω†ÁöÑÈÖçÁΩÆÔºö
    my_api_key = "sk-ZHv49kkwqj8lg05MCzGYF3YFKGwZzdizk419Gv8ylT1pjhOt"
    my_base_url = "https://svip.xty.app/v1"
    my_model_name = "gpt-4.1-mini"

    print(f"üöÄ Connecting to API: {my_base_url}")
    print(f"Model: {my_model_name}")

    # === 2. ÂàùÂßãÂåñ Config ===
    config = BaseConfig(
        save_dir="outputs/test_debug",
        llm_name=my_model_name,
        llm_base_url=my_base_url,
        api_key=my_api_key,  # ËøôÈáåÂøÖÈ°ªÂ°´ÂÜôÁúüÂÆûÁöÑ Key

        embedding_model_name="none",
        temperature=0.0,
        max_new_tokens=2048
    )

    # === 3. ÂàùÂßãÂåñ LLM ===
    try:
        # ‰ΩøÁî®ÂêåÊ≠•ÁöÑ OpenAI_GPT Á±ª (ÂØπÂ∫î‰Ω†Ë¥¥Âá∫Êù•ÁöÑ infer ‰ª£Á†Å)
        llm = CacheOpenAI(cache_dir="outputs/test_debug",llm_name="gpt-4.1-mini",api_key="sk-ZHv49kkwqj8lg05MCzGYF3YFKGwZzdizk419Gv8ylT1pjhOt",llm_base_url="https://svip.xty.app/v1")
        print("‚úÖ LLM Client Initialized successfully.")
    except Exception as e:
        print(f"‚ùå Failed to init LLM: {e}")
        return

    # === 4. ÂàùÂßãÂåñÊèêÂèñÂô® ===
    extractor = PropositionExtractor(llm)

    # === 5. ÂáÜÂ§áÊµãËØïÊï∞ÊçÆ ===
    text = (
        "The anonymous source told The Post that the deal was signed in secret. "
        "'He explicitly promised to pay us,' the source claimed, referring to Governor Smith. "
        "However, Smith's office released a statement denying any such meeting took place. "
        "'The Governor has never met this individual,' the statement read. "
        "But later that evening, a leaked memo suggested that Smith's deputy might have attended in his place."
    )

    entities = [
        "anonymous source", "The Post", "deal", "Governor Smith",
        "Smith's office", "meeting", "leaked memo", "Smith's deputy"
    ]

    print(f"\nüìù Input Text:\n{text}")
    print("\n‚è≥ Extracting Beliefs...")

    # === 6. ËøêË°åÊäΩÂèñ ===
    try:
        # ÂÖ≥Èó≠ cacheÔºåÁ°Æ‰øùÁúüÊ≠£ËØ∑Ê±Ç API
        result = extractor.extract_propositions(
            chunk_key="debug_chunk_001",
            passage=text,
            named_entities=entities,
            use_cache=False
        )

        # === 7. ÊâìÂç∞ÁªìÊûú ===
        print("\n=== ‚ú® Extraction Result ===")

        if not result.propositions:
            print("‚ö†Ô∏è Result is empty.")

        for idx, belief in enumerate(result.propositions):
            source = belief.get('source', 'GlobalContext')
            attitude = belief.get('attitude', 'fact')
            content = belief.get('text', '')
            print(f"{idx + 1}. [{source}] --({attitude})--> \"{content}\"")
            print(f"   Target Entities: {belief.get('entities', [])}")

    except Exception as e:
        print(f"\n‚ùå Error during extraction: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_belief_extraction()
